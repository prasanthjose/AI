Link: https://colab.research.google.com/drive/1DRgvTcMCdKjKvOuxOS6Peo_eKHILCd5H#scrollTo=irTVUE47wNwr

# https://keras.io/
!pip install -q keras
import keras

import numpy as np

from keras.models import Sequential
from keras.layers import Flatten
from keras.layers import Convolution2D
from keras.utils import np_utils
from keras.datasets import mnist



(X_train, y_train), (X_test, y_test) = mnist.load_data()

print (X_train.shape)
from matplotlib import pyplot as plt
%matplotlib inline
plt.imshow(X_train[0])

X_train = X_train.reshape(X_train.shape[0], 28, 28,1)
X_test = X_test.reshape(X_test.shape[0], 28, 28,1)

X_train = X_train.astype('float32')
X_test = X_test.astype('float32')
X_train /= 255
X_test /= 255

y_train[:10]

# Convert 1-dimensional class arrays to 10-dimensional class matrices
Y_train = np_utils.to_categorical(y_train, 10)
Y_test = np_utils.to_categorical(y_test, 10)

Y_train[:10]


from keras.layers import Activation, MaxPooling2D

model = Sequential() 
model.add(Convolution2D(32, 3, 3, activation='relu', input_shape=(28,28,1)))
# Doing convolution with 32 3x3 kernels. activation function is relu. In the fist layer the input size should be mentioned which is a 28X28 picture. I don't know what 1 means.
# RF 3X3
model.add(Convolution2D(64, 3, 3, activation='relu'))
#RF 5X5
model.add(Convolution2D(128, 3, 3, activation='relu'))
#RF 7X7

model.add(MaxPooling2D(pool_size=(2, 2)))
#Doing max pooling to reduce the image size to half (11X11)
#RF 14X14

model.add(Convolution2D(256, 3, 3, activation='relu'))
#RF 16X16
model.add(Convolution2D(512, 3, 3, activation='relu'))
#RF 18X18
model.add(Convolution2D(1024, 3, 3, activation='relu'))
#RF 20X20
model.add(Convolution2D(2048, 3, 3, activation='relu'))
#RF 22X22
model.add(Convolution2D(10, 3, 3, activation='relu'))


model.add(Flatten())
#Flatten the arrays
model.add(Activation('softmax'))
# The output function of the final layer

model.summary()

model.compile(loss='categorical_crossentropy',
             optimizer='adam',
             metrics=['accuracy'])

model.fit(X_train, Y_train, batch_size=32, nb_epoch=10, verbose=1)

score = model.evaluate(X_test, Y_test, verbose=0)

print(score)

y_pred = model.predict(X_test)

print(y_pred[:9])
print(y_test[:9])

#Learning takes too much time. 3 epochs took a day. The accuracy is not improving. The number of layers needs to be reduced.
